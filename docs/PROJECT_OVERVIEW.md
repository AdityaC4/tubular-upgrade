# Tubular Compiler – Project Overview

## Purpose
- Original build for CSE 450 (Compilers), now extended for independent pass-order research.
- Emits WebAssembly Text (WAT) and can be assembled to `.wasm` for execution with Node.js or Wasmtime.

## Directory Map
```
├── Tubular.cpp          # main driver and CLI
├── src/frontend         # lexer, parser, AST
├── src/middle_end       # Control, SymbolTable, passes
├── src/backend          # WAT generator
├── research_tests       # curated benchmarks
├── scripts              # automation (build, data collection, analysis)
└── artifacts/research   # generated datasets (regenerated by scripts)
```

## Key Components
- **Frontend:** Lexer (`lexer.emplex`), `TokenQueue`, recursive-descent parser, rich AST hierarchy.
- **Middle-end:** Pass framework (`Pass`, `PassManager`, `ASTCloner`) plus three optimizations:
  - `FunctionInliningPass`
  - `LoopUnrollingPass`
  - `TailRecursionPass`
  Each pass order is configurable with `--pass-order=inline,unroll,tail`.
- **Backend:** `WATGenerator` visitor emits WAT; helper routines (string support) live in `Tubular::ToWAT`.

## CLI Summary
```
./build/Tubular file.tube [options]
  --no-unroll
  --unroll-factor=N
  --no-inline
  --tail=loop|off
  --pass-order=a,b,c   # permutation of inline/unroll/tail
```

## Testing
- `./make test` runs the legacy regression suite (language + error tests, optimization harnesses, CLI checks).
- Research benchmarks live in `research_tests/` with expected outputs listed in `research_tests/config.json`.

## Automation
- `./scripts/collect_data.py` – rebuilds, sanity-tests, and executes every benchmark/variant/order combination.
- `./scripts/repeat_collection.py` – repeats the sweep (e.g., `--runs 3`) for consistency.
- `./scripts/analyze_research_data.py`, `./scripts/generate_benchmark_features_table.py` – post-process data into tables.

## Getting Started
1. Install dependencies: CMake ≥ 3.16, a C++20 compiler, `wabt` (`wat2wasm`), Node.js, Python 3.8+.
2. Build: `./make`.
3. Run regression tests: `./make test`.
4. Collect research dataset: `./scripts/collect_data.py`.
5. Inspect generated artifacts in `artifacts/research/` and tables in `docs/figures/`.

This overview is intentionally concise; see `README.md` and `docs/DATA_PIPELINE.md` for detailed instructions.
